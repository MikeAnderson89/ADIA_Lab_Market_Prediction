{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-07-13T02:32:58.550269800Z",
     "start_time": "2023-07-13T02:32:55.426532200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import load_model\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-07-13T02:29:40.977526300Z",
     "start_time": "2023-07-13T02:29:40.966026400Z"
    }
   },
   "outputs": [],
   "source": [
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))\n",
    "\n",
    "def convert_to_pairwise(X_train, y_train):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    n_samples = X_train.shape[0]\n",
    "    for i in range(n_samples):\n",
    "        for j in range(i+1, n_samples):\n",
    "            pairs.append([X_train[i, 2:], X_train[j, 2:]])\n",
    "            ids.append([X_train[i, :2], X_train[j, :2]])\n",
    "            labels.append(1 if y_train[i] > y_train[j] else 0)\n",
    "    return np.array(pairs).astype('float32'), np.array(labels).astype('float32'), np.array(ids)\n",
    "\n",
    "def train(X_train: pd.DataFrame, y_train: pd.DataFrame, model_directory_path: str = \"resources\") -> None:\n",
    "    X_train_orig = X_train.copy()\n",
    "    y_train_orig = y_train.copy()\n",
    "    date_list = list(X_train_orig['date'].unique())[-100:]\n",
    "    dates_array = list(split(date_list, 20))\n",
    "\n",
    "    for dates_to_include in dates_array:\n",
    "        X_train = X_train_orig[X_train_orig['date'].isin(dates_to_include)].copy().sort_index()\n",
    "        y_train = y_train_orig[y_train_orig['date'].isin(dates_to_include)].copy().sort_index()\n",
    "\n",
    "        X_train = np.asarray(X_train)\n",
    "\n",
    "        y_train = np.asarray(list(y_train['y']))\n",
    "\n",
    "        print(f\"Loaded Dates for {min(dates_to_include)} to {max(dates_to_include)}\")\n",
    "\n",
    "        #Train or Update Training on Model\n",
    "        model_pathname = Path(model_directory_path) / \"model.keras\"\n",
    "\n",
    "        if model_pathname.is_file():\n",
    "            print(f\"Opened Model for Date {date}\")\n",
    "            #Load Scaler\n",
    "            with open(Path(model_directory_path) / 'scaler.pkl', 'rb') as file:\n",
    "                scaler = pickle.load(file)\n",
    "\n",
    "            #Load PCA\n",
    "            with open(Path(model_directory_path) / 'pca.pkl', 'rb') as file:\n",
    "                pca = pickle.load(file)\n",
    "\n",
    "            #Scaling\n",
    "            X_train[:,2:] = scaler.transform(X_train[:,2:])\n",
    "\n",
    "            #PCA\n",
    "            pca_ids = X_train[:,:2]\n",
    "            pca_features = pca.transform(X_train[:,2:])\n",
    "            X_train_concat = np.concatenate((pca_ids, pca_features), axis=1)\n",
    "            del X_train\n",
    "\n",
    "            X_train_pairs = np.array()\n",
    "            y_train_labels = np.array()\n",
    "            X_train_ids = np.array()\n",
    "\n",
    "            for date in dates_to_include:\n",
    "                #Pairwise Transformation\n",
    "                X_array_from_date = X_train_concat[X_train_concat[,0] == date]\n",
    "                X_train_pair_array, y_train_labels_array, X_train_ids_array = convert_to_pairwise(X_array_from_date, y_train)\n",
    "                X_train_pairs = np.concatenate((X_train_pairs, X_train_pair_array), axis=0)\n",
    "                y_train_labels.append((y_train_labels, y_train_labels_array), axis=0)\n",
    "                X_train_ids.append((X_train_ids, X_train_ids_array), axis=0)\n",
    "                del y_train\n",
    "                del X_array_from_date\n",
    "\n",
    "            del X_train_concat\n",
    "\n",
    "            X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X_train_pairs, y_train_labels, random_state=42, shuffle=True, test_size=0.3)\n",
    "            del X_train_pairs\n",
    "            del y_train_labels\n",
    "\n",
    "            model = load_model(model_pathname)\n",
    "\n",
    "            history = model.fit(\n",
    "                X_train_nn,\n",
    "                y_train_nn,\n",
    "                batch_size=5000,\n",
    "                epochs=10,\n",
    "                validation_data=[X_test_nn, y_test_nn],\n",
    "                callbacks=[mc, early_stopping],\n",
    "                shuffle=False,\n",
    "                use_multiprocessing=True\n",
    "            )\n",
    "\n",
    "        else:\n",
    "\n",
    "            #Scaling\n",
    "            scaler = StandardScaler()\n",
    "            X_train[:,2:] = scaler.fit_transform(X_train[:,2:])\n",
    "\n",
    "            #Save Scaler\n",
    "            with open(Path(model_directory_path) / 'scaler.pkl', 'wb') as file:\n",
    "                pickle.dump(scaler, file)\n",
    "\n",
    "            #PCA\n",
    "            n_components = 40\n",
    "            pca = PCA(n_components=n_components)\n",
    "            pca_ids = X_train[:,:2]\n",
    "            pca_features = pca.fit_transform(X_train[:,2:])\n",
    "            X_train_concat = np.concatenate((pca_ids, pca_features), axis=1)\n",
    "            del X_train\n",
    "\n",
    "            #Save PCA\n",
    "            with open(Path(model_directory_path) / 'pca.pkl', 'wb') as file:\n",
    "                pickle.dump(pca, file)\n",
    "\n",
    "            #Pairwise Transformation\n",
    "            X_train_pairs, y_train_labels, X_train_ids = convert_to_pairwise(X_train_concat, y_train)\n",
    "            del X_train_concat\n",
    "            del y_train\n",
    "\n",
    "            #Get train and test datasets\n",
    "            X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X_train_pairs, y_train_labels, random_state=42, shuffle=True, test_size=0.3)\n",
    "            del X_train_pairs\n",
    "            del y_train_labels\n",
    "\n",
    "            #Neural Network Model\n",
    "            mc = ModelCheckpoint(model_pathname, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=1,\n",
    "                verbose=0,\n",
    "                mode='auto',\n",
    "                baseline=None,\n",
    "                restore_best_weights=True)\n",
    "\n",
    "            model = keras.Sequential([\n",
    "                keras.layers.Dense(800, activation='relu', kernel_initializer='lecun_normal', input_shape=(X_train_nn.shape[1], X_train_nn.shape[2])),\n",
    "                keras.layers.BatchNormalization(),\n",
    "                keras.layers.Dense(500, activation='relu', kernel_initializer='lecun_normal'),\n",
    "                keras.layers.BatchNormalization(),\n",
    "                keras.layers.Dense(250, activation='relu', kernel_initializer='lecun_normal'),\n",
    "                keras.layers.BatchNormalization(),\n",
    "                keras.layers.Dense(100, activation='relu', kernel_initializer='lecun_normal'),\n",
    "                keras.layers.BatchNormalization(),\n",
    "                keras.layers.Flatten(),\n",
    "                keras.layers.Dense(1, activation='sigmoid', kernel_initializer='lecun_normal')\n",
    "            ])\n",
    "\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=3e-4)\n",
    "\n",
    "            model.compile(optimizer=optimizer,\n",
    "                          loss='binary_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            history = model.fit(\n",
    "                X_train_nn,\n",
    "                y_train_nn,\n",
    "                batch_size=10000,\n",
    "                epochs=10,\n",
    "                validation_data=[X_test_nn, y_test_nn],\n",
    "                callbacks=[mc, early_stopping],\n",
    "                shuffle=False,\n",
    "                use_multiprocessing=True\n",
    "            )\n",
    "\n",
    "            model.save(model_pathname)\n",
    "\n",
    "        print(f\"Finished training for Date {date}\")\n",
    "\n",
    "    # make sure that the train function correctly save the trained model\n",
    "    # in the model_directory_path\n",
    "    # print(f\"Saving model in {model_pathname}\")\n",
    "    # joblib.dump(model, model_pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-07-13T02:29:41.837831300Z",
     "start_time": "2023-07-13T02:29:41.822751700Z"
    }
   },
   "outputs": [],
   "source": [
    "def infer(X_test: pd.DataFrame, model_directory_path: str = \"resources\") -> pd.DataFrame:\n",
    "    X_test_orig = X_test.copy()\n",
    "    dates = list(X_test_orig['date'].unique())\n",
    "\n",
    "    result_df = pd.DataFrame(columns=['date', 'id', 'value'])\n",
    "    for date in dates:\n",
    "        X_test = X_test_orig[X_test_orig['date'] == date]\n",
    "\n",
    "        #Dummy 'y' variable\n",
    "        X_test_date = X_test.copy()\n",
    "        X_test_date['y'] = 0\n",
    "\n",
    "        X_test = np.asarray(X_test_date.drop(columns=['y']))\n",
    "\n",
    "        y_test = np.asarray(list(X_test_date['y']))\n",
    "\n",
    "        #Load Scaler\n",
    "        with open(Path(model_directory_path) / 'scaler.pkl', 'rb') as file:\n",
    "            scaler = pickle.load(file)\n",
    "\n",
    "        #Load PCA\n",
    "        with open(Path(model_directory_path) / 'pca.pkl', 'rb') as file:\n",
    "            pca = pickle.load(file)\n",
    "\n",
    "        #Load Model\n",
    "        model_pathname = Path(model_directory_path) / \"model.keras\"\n",
    "        model = load_model(model_pathname)\n",
    "\n",
    "        #Scaling\n",
    "        X_test[:,2:] = scaler.transform(X_test[:,2:])\n",
    "\n",
    "        #PCA\n",
    "        pca_ids = X_test[:,:2]\n",
    "        pca_features = pca.transform(X_test[:,2:])\n",
    "        X_test_concat = np.concatenate((pca_ids, pca_features), axis=1)\n",
    "\n",
    "        #Pairwise Transformation\n",
    "        X_test_pairs, y_test_labels, X_test_ids = convert_to_pairwise(X_test_concat, y_test)\n",
    "\n",
    "        print(f\"Predicting for Date {date} in Test\")\n",
    "        preds = model.predict(X_test_pairs, batch_size=3000)\n",
    "\n",
    "        preds_df_1 = pd.DataFrame({'id': X_test_ids[:,0,1].flatten(), 'date': X_test_ids[:,0,0].flatten(), 'value': preds.flatten()})\n",
    "\n",
    "        result = preds_df_1.groupby(['date', 'id']).mean().reset_index()\n",
    "\n",
    "        result = pd.merge(X_test_date, result, on=['id', 'date'], how='left')\n",
    "\n",
    "        result = result[['date', 'id', 'value']]\n",
    "\n",
    "        lower, upper = -1, 1\n",
    "        result['value'] = [lower + (upper - lower) * x for x in result['value']]\n",
    "\n",
    "        result['value'] = result['value'].fillna(0)\n",
    "\n",
    "        result_df = pd.concat([result_df, result], ignore_index=False, axis=0)\n",
    "\n",
    "        print(f\"Finished predictions for Date {date} in Test\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet('data/X_train.parquet')\n",
    "y_train = pd.read_parquet('data/y_train.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T02:33:07.866858900Z",
     "start_time": "2023-07-13T02:33:05.996916200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Dates for 169 to 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T02:32:06.191405Z",
     "start_time": "2023-07-13T02:29:45.708650400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "268"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(date_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T02:23:29.076996700Z",
     "start_time": "2023-07-13T02:23:29.059297800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "        date                                                 id         0  \\\n0          0  dae29c8061b3176b9208f26afbb96e2ca50886db41902d... -0.909515   \n1          0  2f71f1b5d49fbd131351df95848dc91ab14662af62d4d0... -0.107694   \n2          0  b8d41ef950b69f94c380410f59f47e15666c57b74573b6...  0.092316   \n3          0  cdce060d04ce28a551eaab653cc4b01f5ad878aeb932ec...  4.119639   \n4          0  86f6e6d9407ad3abfab91a3bbfb7ad71553e3f968765b8...  0.109644   \n...      ...                                                ...       ...   \n742665   268  5a18ddc0f252fa17cbd2a5bfe2f3786c0afb5052dd92be...  0.790984   \n742666   268  73c197cf1cb75641710562fe26d4f562c8228847a67949... -1.129492   \n742667   268  bad7ff9ebc5579589e5ef36cb58f962c90c864fd3dfb22...  1.656413   \n742668   268  5b968ca44ac0550be6f31470a96e572cd1c58d36cc26c7...  0.282704   \n742669   268  a42ec1ac915edb35b440184ca52015bf3fdba53c631b1f... -0.813073   \n\n               1         2         3         4         5         6         7  \\\n0       0.388808 -1.535913 -0.133312 -1.826404 -0.532795  0.351273  0.158866   \n1      -0.097967 -0.539599 -0.331276 -0.942609 -0.054123 -1.212772  1.688034   \n2       0.052596 -0.652025  1.218241  0.382968 -0.861838 -0.318937 -0.744261   \n3       1.018918  3.687519  1.597563  0.055918 -1.406041  0.652994  0.251138   \n4      -0.290280 -0.278987 -0.603259  0.136952 -1.725076 -0.062219 -0.183102   \n...          ...       ...       ...       ...       ...       ...       ...   \n742665  1.560877 -0.328996 -0.190068  0.314971 -0.001609  0.313957 -0.315743   \n742666  0.696247 -1.494771 -0.404022  0.909996 -0.658659  0.688591  1.634416   \n742667 -1.267060  0.748902 -0.196263  0.831206 -1.590837  3.079856  0.498583   \n742668  0.156104 -1.165022  0.513334 -1.111948 -1.368465 -1.347184 -0.926533   \n742669 -0.824916 -0.368725  0.136837  0.270865  0.710876  0.734015 -1.233695   \n\n        ...       451       452       453       454       455       456  \\\n0       ... -0.731349 -0.456020 -0.257331  0.396074  0.318007 -0.538754   \n1       ...  0.610428 -0.984907 -0.429806  0.199055  0.202587  1.612578   \n2       ...  0.212365 -0.046016  1.147463  0.696961 -0.574426  1.255969   \n3       ...  1.254787 -1.155922 -1.108540 -2.046100  1.311100 -0.322965   \n4       ... -2.007721 -0.482311 -0.269142 -0.899796  1.083332  0.674665   \n...     ...       ...       ...       ...       ...       ...       ...   \n742665  ... -1.450422 -1.044100  0.631455 -1.322626 -0.407846  0.578026   \n742666  ... -0.475011  0.319023 -1.038112  0.222924  0.804017 -0.969177   \n742667  ... -0.010330 -0.426130 -0.624393 -0.236483 -0.244052  1.280749   \n742668  ...  0.411093  0.225324 -0.112838 -0.366831 -0.385833 -0.301606   \n742669  ...  0.134728  0.133413 -0.904207 -0.430508 -1.598422 -0.819337   \n\n             457       458       459       460  \n0      -0.625193 -0.753419  0.154403  1.069385  \n1       0.302153 -0.165713  0.905807  0.083180  \n2       0.270394  1.272939 -0.643112  0.433585  \n3       0.999248 -1.238640  0.882844 -1.333590  \n4      -1.095657 -0.402669  0.677189  0.319992  \n...          ...       ...       ...       ...  \n742665  0.830650  1.414314 -0.845734  0.399335  \n742666 -1.011879 -0.921781 -0.067543  0.491890  \n742667 -2.001158 -1.036838 -1.959235 -2.534523  \n742668  0.395659 -0.895311 -0.819201 -0.996246  \n742669  0.012623  0.624302 -0.532539  0.105044  \n\n[742670 rows x 463 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>id</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>451</th>\n      <th>452</th>\n      <th>453</th>\n      <th>454</th>\n      <th>455</th>\n      <th>456</th>\n      <th>457</th>\n      <th>458</th>\n      <th>459</th>\n      <th>460</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>dae29c8061b3176b9208f26afbb96e2ca50886db41902d...</td>\n      <td>-0.909515</td>\n      <td>0.388808</td>\n      <td>-1.535913</td>\n      <td>-0.133312</td>\n      <td>-1.826404</td>\n      <td>-0.532795</td>\n      <td>0.351273</td>\n      <td>0.158866</td>\n      <td>...</td>\n      <td>-0.731349</td>\n      <td>-0.456020</td>\n      <td>-0.257331</td>\n      <td>0.396074</td>\n      <td>0.318007</td>\n      <td>-0.538754</td>\n      <td>-0.625193</td>\n      <td>-0.753419</td>\n      <td>0.154403</td>\n      <td>1.069385</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2f71f1b5d49fbd131351df95848dc91ab14662af62d4d0...</td>\n      <td>-0.107694</td>\n      <td>-0.097967</td>\n      <td>-0.539599</td>\n      <td>-0.331276</td>\n      <td>-0.942609</td>\n      <td>-0.054123</td>\n      <td>-1.212772</td>\n      <td>1.688034</td>\n      <td>...</td>\n      <td>0.610428</td>\n      <td>-0.984907</td>\n      <td>-0.429806</td>\n      <td>0.199055</td>\n      <td>0.202587</td>\n      <td>1.612578</td>\n      <td>0.302153</td>\n      <td>-0.165713</td>\n      <td>0.905807</td>\n      <td>0.083180</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>b8d41ef950b69f94c380410f59f47e15666c57b74573b6...</td>\n      <td>0.092316</td>\n      <td>0.052596</td>\n      <td>-0.652025</td>\n      <td>1.218241</td>\n      <td>0.382968</td>\n      <td>-0.861838</td>\n      <td>-0.318937</td>\n      <td>-0.744261</td>\n      <td>...</td>\n      <td>0.212365</td>\n      <td>-0.046016</td>\n      <td>1.147463</td>\n      <td>0.696961</td>\n      <td>-0.574426</td>\n      <td>1.255969</td>\n      <td>0.270394</td>\n      <td>1.272939</td>\n      <td>-0.643112</td>\n      <td>0.433585</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>cdce060d04ce28a551eaab653cc4b01f5ad878aeb932ec...</td>\n      <td>4.119639</td>\n      <td>1.018918</td>\n      <td>3.687519</td>\n      <td>1.597563</td>\n      <td>0.055918</td>\n      <td>-1.406041</td>\n      <td>0.652994</td>\n      <td>0.251138</td>\n      <td>...</td>\n      <td>1.254787</td>\n      <td>-1.155922</td>\n      <td>-1.108540</td>\n      <td>-2.046100</td>\n      <td>1.311100</td>\n      <td>-0.322965</td>\n      <td>0.999248</td>\n      <td>-1.238640</td>\n      <td>0.882844</td>\n      <td>-1.333590</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>86f6e6d9407ad3abfab91a3bbfb7ad71553e3f968765b8...</td>\n      <td>0.109644</td>\n      <td>-0.290280</td>\n      <td>-0.278987</td>\n      <td>-0.603259</td>\n      <td>0.136952</td>\n      <td>-1.725076</td>\n      <td>-0.062219</td>\n      <td>-0.183102</td>\n      <td>...</td>\n      <td>-2.007721</td>\n      <td>-0.482311</td>\n      <td>-0.269142</td>\n      <td>-0.899796</td>\n      <td>1.083332</td>\n      <td>0.674665</td>\n      <td>-1.095657</td>\n      <td>-0.402669</td>\n      <td>0.677189</td>\n      <td>0.319992</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>742665</th>\n      <td>268</td>\n      <td>5a18ddc0f252fa17cbd2a5bfe2f3786c0afb5052dd92be...</td>\n      <td>0.790984</td>\n      <td>1.560877</td>\n      <td>-0.328996</td>\n      <td>-0.190068</td>\n      <td>0.314971</td>\n      <td>-0.001609</td>\n      <td>0.313957</td>\n      <td>-0.315743</td>\n      <td>...</td>\n      <td>-1.450422</td>\n      <td>-1.044100</td>\n      <td>0.631455</td>\n      <td>-1.322626</td>\n      <td>-0.407846</td>\n      <td>0.578026</td>\n      <td>0.830650</td>\n      <td>1.414314</td>\n      <td>-0.845734</td>\n      <td>0.399335</td>\n    </tr>\n    <tr>\n      <th>742666</th>\n      <td>268</td>\n      <td>73c197cf1cb75641710562fe26d4f562c8228847a67949...</td>\n      <td>-1.129492</td>\n      <td>0.696247</td>\n      <td>-1.494771</td>\n      <td>-0.404022</td>\n      <td>0.909996</td>\n      <td>-0.658659</td>\n      <td>0.688591</td>\n      <td>1.634416</td>\n      <td>...</td>\n      <td>-0.475011</td>\n      <td>0.319023</td>\n      <td>-1.038112</td>\n      <td>0.222924</td>\n      <td>0.804017</td>\n      <td>-0.969177</td>\n      <td>-1.011879</td>\n      <td>-0.921781</td>\n      <td>-0.067543</td>\n      <td>0.491890</td>\n    </tr>\n    <tr>\n      <th>742667</th>\n      <td>268</td>\n      <td>bad7ff9ebc5579589e5ef36cb58f962c90c864fd3dfb22...</td>\n      <td>1.656413</td>\n      <td>-1.267060</td>\n      <td>0.748902</td>\n      <td>-0.196263</td>\n      <td>0.831206</td>\n      <td>-1.590837</td>\n      <td>3.079856</td>\n      <td>0.498583</td>\n      <td>...</td>\n      <td>-0.010330</td>\n      <td>-0.426130</td>\n      <td>-0.624393</td>\n      <td>-0.236483</td>\n      <td>-0.244052</td>\n      <td>1.280749</td>\n      <td>-2.001158</td>\n      <td>-1.036838</td>\n      <td>-1.959235</td>\n      <td>-2.534523</td>\n    </tr>\n    <tr>\n      <th>742668</th>\n      <td>268</td>\n      <td>5b968ca44ac0550be6f31470a96e572cd1c58d36cc26c7...</td>\n      <td>0.282704</td>\n      <td>0.156104</td>\n      <td>-1.165022</td>\n      <td>0.513334</td>\n      <td>-1.111948</td>\n      <td>-1.368465</td>\n      <td>-1.347184</td>\n      <td>-0.926533</td>\n      <td>...</td>\n      <td>0.411093</td>\n      <td>0.225324</td>\n      <td>-0.112838</td>\n      <td>-0.366831</td>\n      <td>-0.385833</td>\n      <td>-0.301606</td>\n      <td>0.395659</td>\n      <td>-0.895311</td>\n      <td>-0.819201</td>\n      <td>-0.996246</td>\n    </tr>\n    <tr>\n      <th>742669</th>\n      <td>268</td>\n      <td>a42ec1ac915edb35b440184ca52015bf3fdba53c631b1f...</td>\n      <td>-0.813073</td>\n      <td>-0.824916</td>\n      <td>-0.368725</td>\n      <td>0.136837</td>\n      <td>0.270865</td>\n      <td>0.710876</td>\n      <td>0.734015</td>\n      <td>-1.233695</td>\n      <td>...</td>\n      <td>0.134728</td>\n      <td>0.133413</td>\n      <td>-0.904207</td>\n      <td>-0.430508</td>\n      <td>-1.598422</td>\n      <td>-0.819337</td>\n      <td>0.012623</td>\n      <td>0.624302</td>\n      <td>-0.532539</td>\n      <td>0.105044</td>\n    </tr>\n  </tbody>\n</table>\n<p>742670 rows Ã— 463 columns</p>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in range(dates_length):\n",
    "    begin_date =\n",
    "    end_date =\n",
    "    X_train = X_train_orig[X_train_orig['date'] == date].copy()\n",
    "    y_train = y_train_orig[y_train_orig['date'] == date].copy()\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "\n",
    "    y_train = np.asarray(list(y_train['y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T01:47:40.302623600Z",
     "start_time": "2023-07-13T01:47:40.148589200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "date_thing = math.ceil(dates_length / 25) + 1\n",
    "for i in range(1, date_thing):\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T01:51:38.023618Z",
     "start_time": "2023-07-13T01:51:38.020118800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "date_list = list(X_train['date'].unique())[-100:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T02:21:56.967240800Z",
     "start_time": "2023-07-13T02:21:56.947217900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() missing required argument 'shape' (pos 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m X_train_pairs \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m y_train_labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty()\n\u001B[0;32m      3\u001B[0m X_train_ids \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty()\n",
      "\u001B[1;31mTypeError\u001B[0m: empty() missing required argument 'shape' (pos 0)"
     ]
    }
   ],
   "source": [
    "X_train_pairs = np.empty()\n",
    "y_train_labels = np.empty()\n",
    "X_train_ids = np.empty()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T02:41:49.739095300Z",
     "start_time": "2023-07-13T02:41:49.728595700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T01:52:57.362082200Z",
     "start_time": "2023-07-13T01:52:57.343584Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "dates_array = list(split(dates_list, 10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T01:56:58.208826800Z",
     "start_time": "2023-07-13T01:56:58.203146Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
      "[27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "[54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80]\n",
      "[81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107]\n",
      "[108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134]\n",
      "[135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161]\n",
      "[162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188]\n",
      "[189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]\n",
      "[216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242]\n",
      "[243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268]\n"
     ]
    }
   ],
   "source": [
    "for i in dates_array:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T01:57:04.844820100Z",
     "start_time": "2023-07-13T01:57:04.834798400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "date_list = list(X_train['date'].unique())[-100:]\n",
    "dates_array = list(split(date_list, 20))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T02:25:16.057340300Z",
     "start_time": "2023-07-13T02:25:16.043843200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[[169, 170, 171, 172, 173],\n [174, 175, 176, 177, 178],\n [179, 180, 181, 182, 183],\n [184, 185, 186, 187, 188],\n [189, 190, 191, 192, 193],\n [194, 195, 196, 197, 198],\n [199, 200, 201, 202, 203],\n [204, 205, 206, 207, 208],\n [209, 210, 211, 212, 213],\n [214, 215, 216, 217, 218],\n [219, 220, 221, 222, 223],\n [224, 225, 226, 227, 228],\n [229, 230, 231, 232, 233],\n [234, 235, 236, 237, 238],\n [239, 240, 241, 242, 243],\n [244, 245, 246, 247, 248],\n [249, 250, 251, 252, 253],\n [254, 255, 256, 257, 258],\n [259, 260, 261, 262, 263],\n [264, 265, 266, 267, 268]]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T02:25:16.428942100Z",
     "start_time": "2023-07-13T02:25:16.411933100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_train = X_train[X_train['date'] <= 10]\n",
    "x = np.asarray(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T02:33:35.520895700Z",
     "start_time": "2023-07-13T02:33:35.376874100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1,\n        'a9580bb984c328091d2b70b497f97dce963bfd785621c80a4ba47d357863335e',\n        -0.08658834546804428, ..., -1.7963533401489258,\n        -0.25102466344833374, 1.7424898147583008],\n       [1,\n        '56bccba09d92107ecf3af54246dcc504e059c6ea7917d61a303ce1976f6343bb',\n        1.5079907178878784, ..., 1.211098551750183, 0.6537860035896301,\n        -1.0638591051101685],\n       [1,\n        '0e3de002c861737e58efaed85626573c3d0ce8d6de9537ec252f81adceff7205',\n        -1.2383681535720825, ..., -0.5632125735282898,\n        1.4093866348266602, -0.1598205417394638],\n       ...,\n       [1,\n        '9e2c934ee7036e4c009f854cbad7c1918c15affa87de087fefd3a2fceec16387',\n        0.9924005270004272, ..., 0.15136367082595825, 0.984168291091919,\n        0.21882113814353943],\n       [1,\n        '4b66c74a9c71dff9bc7acf34704df667f6fdc2aa364c30c9dca8e4ab7e01bffb',\n        0.32769083976745605, ..., 1.0924345254898071, 1.4107588529586792,\n        0.8826435804367065],\n       [1,\n        '76bf116e4e803ab83090712c79e0350f20d9cd21bf6de7218aaf12d76ca5e7b0',\n        0.11399828642606735, ..., -1.1468580961227417,\n        0.039978913962841034, -0.5922620296478271]], dtype=object)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[x[:,0] == 1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T02:34:55.368970500Z",
     "start_time": "2023-07-13T02:34:55.362972400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
